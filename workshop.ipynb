{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a RAG System Locally with Ollama, LlamaIndex, and Chroma DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 0 - Install Workshop Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the workshop, ensure all necessary dependencies are installed in your Python environment. Use the following steps to set up your environment.\n",
    "\n",
    "### Step 1: Create a Virtual Environment\n",
    "\n",
    "Create and activate a virtual environment to isolate the workshop dependencies. For this workshop, we use **Python 3.11**. Choose between **venv** or **conda** (using Mamba for efficiency).\n",
    "\n",
    "##### Using `venv`\n",
    "\n",
    "On Linux/Mac:\n",
    "  ```bash\n",
    "  python3.11 -m venv local-rag\n",
    "  source local-rag/bin/activate\n",
    "  ```\n",
    "On Windows:\n",
    "  ```bash\n",
    "  python3.11 -m venv local-rag\n",
    "  local-rag\\Scripts\\activate\n",
    "  ```\n",
    "\n",
    "##### Using `conda`\n",
    "\n",
    "   ```bash\n",
    "   conda create -n local-rag python=3.11\n",
    "   conda activate local-rag\n",
    "   ```\n",
    "\n",
    "### Step 2: Install Required Packages\n",
    "\n",
    "Install all the required dependencies:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### Step 3: Verify Installation\n",
    "\n",
    "Check that the key packages are installed correctly by importing them in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/rhita.mamou/Downloads/lauzhack-workshop-2024-main/',\n",
       " '/Users/rhita.mamou/Downloads/lauzhack-workshop-2024-main/',\n",
       " '/opt/anaconda3/envs/dev/lib/python312.zip',\n",
       " '/opt/anaconda3/envs/dev/lib/python3.12',\n",
       " '/opt/anaconda3/envs/dev/lib/python3.12/lib-dynload',\n",
       " '',\n",
       " '/opt/anaconda3/envs/dev/lib/python3.12/site-packages']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/Users/rhita.mamou/Downloads/lauzhack-workshop-2024-main/')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies installed successfully!\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import llama_index\n",
    "import ollama\n",
    "\n",
    "print(\"Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Setting up Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Ollama\n",
    "\n",
    "First, download and install Ollama from the official website: [https://ollama.com/download/](https://ollama.com/download/).\n",
    "\n",
    "### Pull Required Models\n",
    "\n",
    "Open a terminal and run the following commands to download the necessary models:\n",
    "\n",
    "1. Pull the `llama3` model:\n",
    "   ```bash\n",
    "   ollama pull llama3\n",
    "   ```\n",
    "\n",
    "2. Pull the Nomic embedding model if required:\n",
    "   ```bash\n",
    "   ollama pull nomic\n",
    "   ```\n",
    "\n",
    "### Run the Model\n",
    "\n",
    "Once the models are installed, you can run the `llama3` model and test it by writing some prompts. Use the following command:\n",
    "\n",
    "```bash\n",
    "ollama run llama3\n",
    "```\n",
    "\n",
    "Type a prompt and observe the output to ensure everything is working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact with Ollama in Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPFL (École polytechnique fédérale de Lausanne) is a Swiss research university located in Lausanne, Switzerland. It is one of the most prestigious and highly regarded institutions of higher education in Switzerland.\n",
      "\n",
      "EPFL was founded in 1858 as the \"Federal Polytechnic School\" with the goal of providing a rigorous education in science, technology, engineering, and mathematics (STEM) fields. Over time, it has expanded to include programs in other areas such as business, law, social sciences, and humanities.\n",
      "\n",
      "Today, EPFL is known for its strong research focus, particularly in the fields of physics, biology, chemistry, and computer science. It is consistently ranked among the top universities globally in various rankings, including QS World University Rankings, Times Higher Education World University Rankings, and US News Best Global Universities Rankings.\n",
      "\n",
      "EPFL has a number of unique features, including:\n",
      "\n",
      "* A strong focus on interdisciplinary research and collaboration\n",
      "* A highly international student body, with students from over 120 countries\n",
      "* A faculty that includes many renowned researchers and scientists in their fields\n",
      "* Strong connections to industry and the Swiss entrepreneurial ecosystem\n",
      "\n",
      "Some notable alumni of EPFL include entrepreneurs such as Thomas Sonnenschein (founding partner of Swisscom) and Christian Kambundji (Swiss footballer).\n",
      "\n",
      "Overall, EPFL is a highly respected institution known for its academic excellence, innovative research, and strong connections to industry and society."
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.generate(model=\"llama3.2\", prompt=\"What is EPFL?\", stream=True)\n",
    "\n",
    "for r in response:\n",
    "    print(r[\"response\"], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Getting Started with LlamaIndex and ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LlamaIndex** ([official site](https://llamaindex.ai)) is a framework for connecting LLMs with data sources, enabling efficient retrieval and interaction with structured or unstructured data.\n",
    "\n",
    "**Chroma** ([official site](https://www.trychroma.com)) is a vector database designed for managing embeddings and serving as a retrieval layer for LLM applications.\n",
    "\n",
    "In this exercise, we’ll explore how to set up and use LlamaIndex to index and retrieve data in a **Chroma** database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Let's download a PDF\n",
    "\n",
    "You can start by adding documents to the `./docs` folder. If you don't know what to use, we suggest downloading the PDF at the following link:\n",
    "\n",
    "https://observationofalostsoul.wordpress.com/wp-content/uploads/2011/05/the-gospel-of-the-flying-spaghetti-monster.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set Up Chroma as the Storage Backend\n",
    "\n",
    "Initialize the Chroma database and configure it for use with LlamaIndex. Here, we create an **Ephemeral Client** and collection, which stores data temporarily in memory without persisting it. This is ideal for testing and experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.EphemeralClient()\n",
    "chroma_collection = chroma_client.get_or_create_collection(\"mydocs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create a **Persistent Client** that will preserve your database across sessions with:\n",
    "\n",
    "```python\n",
    "client = chromadb.PersistentClient(path=\"/path/to/save/to\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set Up LlamaIndex connectors\n",
    "\n",
    "Configure LlamaIndex to connect with Chroma as the vector store and set up a storage context. A **storage context** is an abstraction that manages how data is stored and retrieved, enabling seamless integration with different storage backends like Chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load and explore documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use LlamaIndex's `SimpleDirectoryReader` to **ingest documents from a directory**. This utility reads files from a specified directory and prepares them for indexing by splitting the content into manageable chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"../docs\", recursive=True).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_': 'a0113a63-2ab8-468a-9ef4-bc949cbb828c',\n",
       " 'embedding': None,\n",
       " 'metadata': {'page_label': '1',\n",
       "  'file_name': 'the-gospel-of-the-flying-spaghetti-monster.pdf',\n",
       "  'file_path': '/Users/rhita.mamou/Downloads/lauzhack-workshop-2024-main/code/../docs/the-gospel-of-the-flying-spaghetti-monster.pdf',\n",
       "  'file_type': 'application/pdf',\n",
       "  'file_size': 9742787,\n",
       "  'creation_date': '2024-11-14',\n",
       "  'last_modified_date': '2024-11-14'},\n",
       " 'excluded_embed_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'excluded_llm_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'relationships': {},\n",
       " 'text': '',\n",
       " 'mimetype': 'text/plain',\n",
       " 'start_char_idx': None,\n",
       " 'end_char_idx': None,\n",
       " 'text_template': '{metadata_str}\\n\\n{content}',\n",
       " 'metadata_template': '{key}: {value}',\n",
       " 'metadata_seperator': '\\n',\n",
       " 'class_name': 'Document'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the content of the documents further with a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "\n",
    "def data_to_df(nodes: List[TextNode]):\n",
    "    \"\"\"Convert a list of TextNode objects to a pandas DataFrame.\"\"\"\n",
    "    return pd.DataFrame([node.dict() for node in nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_</th>\n",
       "      <th>embedding</th>\n",
       "      <th>metadata</th>\n",
       "      <th>excluded_embed_metadata_keys</th>\n",
       "      <th>excluded_llm_metadata_keys</th>\n",
       "      <th>relationships</th>\n",
       "      <th>text</th>\n",
       "      <th>mimetype</th>\n",
       "      <th>start_char_idx</th>\n",
       "      <th>end_char_idx</th>\n",
       "      <th>text_template</th>\n",
       "      <th>metadata_template</th>\n",
       "      <th>metadata_seperator</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a0113a63-2ab8-468a-9ef4-bc949cbb828c</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '1', 'file_name': 'the-gospel-o...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{}</td>\n",
       "      <td></td>\n",
       "      <td>text/plain</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0b2d8729-c856-4177-8eac-61a34d53e23f</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '2', 'file_name': 'the-gospel-o...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{}</td>\n",
       "      <td>BOBBY HENDERSON</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ec9ce1b-fe85-40a4-8700-919a6166f9f5</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '3', 'file_name': 'the-gospel-o...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{}</td>\n",
       "      <td>A Villard Books Trade Paperback Original \\nCop...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bd9642ca-f78e-4a94-99de-52d547ea566f</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '4', 'file_name': 'the-gospel-o...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{}</td>\n",
       "      <td>In the beginning was the Word, \\nand the Word ...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad9d66b4-bd2b-46f6-95c1-cca78d1ed072</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '5', 'file_name': 'the-gospel-o...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{}</td>\n",
       "      <td>Ackn owl ed gm en ts \\nDELIVERING A DIVINE MES...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Document</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id_ embedding  \\\n",
       "0  a0113a63-2ab8-468a-9ef4-bc949cbb828c      None   \n",
       "1  0b2d8729-c856-4177-8eac-61a34d53e23f      None   \n",
       "2  3ec9ce1b-fe85-40a4-8700-919a6166f9f5      None   \n",
       "3  bd9642ca-f78e-4a94-99de-52d547ea566f      None   \n",
       "4  ad9d66b4-bd2b-46f6-95c1-cca78d1ed072      None   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'page_label': '1', 'file_name': 'the-gospel-o...   \n",
       "1  {'page_label': '2', 'file_name': 'the-gospel-o...   \n",
       "2  {'page_label': '3', 'file_name': 'the-gospel-o...   \n",
       "3  {'page_label': '4', 'file_name': 'the-gospel-o...   \n",
       "4  {'page_label': '5', 'file_name': 'the-gospel-o...   \n",
       "\n",
       "                        excluded_embed_metadata_keys  \\\n",
       "0  [file_name, file_type, file_size, creation_dat...   \n",
       "1  [file_name, file_type, file_size, creation_dat...   \n",
       "2  [file_name, file_type, file_size, creation_dat...   \n",
       "3  [file_name, file_type, file_size, creation_dat...   \n",
       "4  [file_name, file_type, file_size, creation_dat...   \n",
       "\n",
       "                          excluded_llm_metadata_keys relationships  \\\n",
       "0  [file_name, file_type, file_size, creation_dat...            {}   \n",
       "1  [file_name, file_type, file_size, creation_dat...            {}   \n",
       "2  [file_name, file_type, file_size, creation_dat...            {}   \n",
       "3  [file_name, file_type, file_size, creation_dat...            {}   \n",
       "4  [file_name, file_type, file_size, creation_dat...            {}   \n",
       "\n",
       "                                                text    mimetype  \\\n",
       "0                                                     text/plain   \n",
       "1                                   BOBBY HENDERSON   text/plain   \n",
       "2  A Villard Books Trade Paperback Original \\nCop...  text/plain   \n",
       "3  In the beginning was the Word, \\nand the Word ...  text/plain   \n",
       "4  Ackn owl ed gm en ts \\nDELIVERING A DIVINE MES...  text/plain   \n",
       "\n",
       "  start_char_idx end_char_idx                text_template metadata_template  \\\n",
       "0           None         None  {metadata_str}\\n\\n{content}    {key}: {value}   \n",
       "1           None         None  {metadata_str}\\n\\n{content}    {key}: {value}   \n",
       "2           None         None  {metadata_str}\\n\\n{content}    {key}: {value}   \n",
       "3           None         None  {metadata_str}\\n\\n{content}    {key}: {value}   \n",
       "4           None         None  {metadata_str}\\n\\n{content}    {key}: {value}   \n",
       "\n",
       "  metadata_seperator class_name  \n",
       "0                 \\n   Document  \n",
       "1                 \\n   Document  \n",
       "2                 \\n   Document  \n",
       "3                 \\n   Document  \n",
       "4                 \\n   Document  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df = data_to_df(documents)\n",
    "\n",
    "document_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe several attributes, including `metadata`, `text`, `text_template`, and others. Let's focus on these three key categories:\n",
    "\n",
    "- **`metadata`**: This attribute contains additional information about the document, such as its source, creation date, or tags that can be used for filtering or retrieval purposes.\n",
    "- **`text`**: The main content of the document, representing the raw textual data that will be indexed and queried.\n",
    "- **`text_template`**: A structured format or schema for the document's text, often used to define how the content should be presented or processed during queries. \n",
    "\n",
    "These attributes play distinct roles in organizing and interacting with your data. Feel free to explore the different attributes at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Index and the documents\n",
    "\n",
    "To ingest documents into an index, we will need an embedder model to convert the document content into vector representations. These embeddings enable efficient similarity searches and retrievals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dev/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In LlamaIndex, we can create an index using the `VectorStoreIndex` class, which enables efficient storage and retrieval of document embeddings and integrates with various storage backends and embedding models. We use here the chroma collection we previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 178/178 [00:00<00:00, 5057.55it/s]\n",
      "Generating embeddings: 100%|██████████| 178/178 [00:14<00:00, 12.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Query the Index for Retrieval\n",
    "\n",
    "Once the documents are indexed, we can perform retrieval on them. This allows us to ask questions or search for relevant content based on the embeddings stored in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_</th>\n",
       "      <th>embedding</th>\n",
       "      <th>metadata</th>\n",
       "      <th>excluded_embed_metadata_keys</th>\n",
       "      <th>excluded_llm_metadata_keys</th>\n",
       "      <th>relationships</th>\n",
       "      <th>text</th>\n",
       "      <th>mimetype</th>\n",
       "      <th>start_char_idx</th>\n",
       "      <th>end_char_idx</th>\n",
       "      <th>text_template</th>\n",
       "      <th>metadata_template</th>\n",
       "      <th>metadata_seperator</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48da01ff-dff1-4e0d-a723-31092163e064</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '66', 'file_name': 'the-gospel-...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{'NodeRelationship.SOURCE': {'node_id': 'fdb5a...</td>\n",
       "      <td>Key Moments in FSM History • • 59 \\nOriginally...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>0</td>\n",
       "      <td>363</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>TextNode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5674cad3-3450-4982-8688-911324e27ebc</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '138', 'file_name': 'the-gospel...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{'NodeRelationship.SOURCE': {'node_id': 'f1f6f...</td>\n",
       "      <td>1 34« -The Gospel of the Flying Spaghetti Mons...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>TextNode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cb2a52c3-77ee-4ac9-a8ae-c53421d8201d</td>\n",
       "      <td>None</td>\n",
       "      <td>{'page_label': '89', 'file_name': 'the-gospel-...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>[file_name, file_type, file_size, creation_dat...</td>\n",
       "      <td>{'NodeRelationship.SOURCE': {'node_id': '22f42...</td>\n",
       "      <td>82 • • The Gospel of the Flying Spaghetti Mons...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>0</td>\n",
       "      <td>2193</td>\n",
       "      <td>{metadata_str}\\n\\n{content}</td>\n",
       "      <td>{key}: {value}</td>\n",
       "      <td>\\n</td>\n",
       "      <td>TextNode</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id_ embedding  \\\n",
       "0  48da01ff-dff1-4e0d-a723-31092163e064      None   \n",
       "1  5674cad3-3450-4982-8688-911324e27ebc      None   \n",
       "2  cb2a52c3-77ee-4ac9-a8ae-c53421d8201d      None   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'page_label': '66', 'file_name': 'the-gospel-...   \n",
       "1  {'page_label': '138', 'file_name': 'the-gospel...   \n",
       "2  {'page_label': '89', 'file_name': 'the-gospel-...   \n",
       "\n",
       "                        excluded_embed_metadata_keys  \\\n",
       "0  [file_name, file_type, file_size, creation_dat...   \n",
       "1  [file_name, file_type, file_size, creation_dat...   \n",
       "2  [file_name, file_type, file_size, creation_dat...   \n",
       "\n",
       "                          excluded_llm_metadata_keys  \\\n",
       "0  [file_name, file_type, file_size, creation_dat...   \n",
       "1  [file_name, file_type, file_size, creation_dat...   \n",
       "2  [file_name, file_type, file_size, creation_dat...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  {'NodeRelationship.SOURCE': {'node_id': 'fdb5a...   \n",
       "1  {'NodeRelationship.SOURCE': {'node_id': 'f1f6f...   \n",
       "2  {'NodeRelationship.SOURCE': {'node_id': '22f42...   \n",
       "\n",
       "                                                text    mimetype  \\\n",
       "0  Key Moments in FSM History • • 59 \\nOriginally...  text/plain   \n",
       "1  1 34« -The Gospel of the Flying Spaghetti Mons...  text/plain   \n",
       "2  82 • • The Gospel of the Flying Spaghetti Mons...  text/plain   \n",
       "\n",
       "   start_char_idx  end_char_idx                text_template  \\\n",
       "0               0           363  {metadata_str}\\n\\n{content}   \n",
       "1               0          2198  {metadata_str}\\n\\n{content}   \n",
       "2               0          2193  {metadata_str}\\n\\n{content}   \n",
       "\n",
       "  metadata_template metadata_seperator class_name  \n",
       "0    {key}: {value}                 \\n   TextNode  \n",
       "1    {key}: {value}                 \\n   TextNode  \n",
       "2    {key}: {value}                 \\n   TextNode  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = index.as_retriever(\n",
    "    similarity_top_k=3,\n",
    ")\n",
    "\n",
    "nodes_with_score = retriever.retrieve(\"What is the Flying Spaghetti Monster?\")\n",
    "nodes = [n.node for n in nodes_with_score]\n",
    "data_to_df(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You've retrieved your first data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Your First RAG!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a Retrieval-Augmented Generation (RAG) system, you need a Large Language Model (LLM) to generate answers to your queries by combining retrieved knowledge with the model's reasoning capabilities. At this point, Ollama comes to help as the LLM powering your RAG system. We set it up for LlamaIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3.2\", request_timeout=120.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is ready for querying your data. You can define a query engine and start asking it questions. Congrats, You have a working RAG!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    similarity_top_k=3,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What is the Flying Spaghetti Monster?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Flying Spaghetti Monster is a supreme being that created the world according to the author of \"The Gospel of the Flying Spaghetti Monster\". It has left its mark on every continent and culture, leaving evidence of its existence in various forms such as pastas, geographical features, and even fossil records. The FSM's hand can be seen in human cultures dating back as far as one million years, from the discovery of pasta to the Acheulean Stone Twirling Spaghetti Fork found in France."
     ]
    }
   ],
   "source": [
    "response.print_response_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going further..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt template\n",
    "\n",
    "LlamaIndex offers an easy way to improve the generated answer by prompting the LLM with a custom template, in which the relevant context will be fed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "template = (\n",
    "    \"As a devoted Pastafarian scholar touched by His Noodly Appendage, you shall defend our pasta-based teachings.\\n\\n\"\n",
    "    \"Sacred commandments:\\n\"\n",
    "    \"- Keep answers CONCISE (2-3 paragraphs max)\\n\"\n",
    "    \"- Cite the Sacred Texts below\\n\"\n",
    "    \"- Use pasta metaphors liberally\\n\"\n",
    "    \"- Defend with noodly passion\\n\\n\"\n",
    "    \"Sacred texts:\\n\"\n",
    "    \"-----------------------------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"-----------------------------------------\\n\\n\"\n",
    "    \"Question from seeker:\\n\"\n",
    "    \"{query_str}\\n\\n\"\n",
    "    \"Answer with fervor, citing texts. Be passionate but brief. R'amen.\"\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    similartiy_top_k=3,\n",
    "    streaming=True,\n",
    "    text_qa_template=qa_template,\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What is the Flying Spaghetti Monster?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear seeker of truth, let me enlighten you on the majesty of our beloved FSM! According to page 138 of \"The Gospel of the Flying Spaghetti Monster\", \"There is irrevocable proof that the Flying Spaghetti Monster (FSM) created the world\" (Lauzhack-workshop-2024-main/code/../docs/the-gospel-of-the-flying-spaghetti-monster.pdf). Our FSM, a benevolent deity with a Noodly Appendage, has touched every continent and culture, leaving an indelible mark of His divine presence.\n",
      "\n",
      "As the great historian and scholar, Toby Leonard, so eloquently puts it: \"Some people point to selective fossil evidence and then use fuzzy interpolation to explain gaps in the fossil record... But I have factual proof that on every continent all that was created was touched by His Noodly Appendage.\" (Lauzhack-workshop-2024-main/code/../docs/the-gospel-of-the-flying-spaghetti-monster.pdf) The FSM's presence is palpable, from the Danube River to the \"Acheulean Stone Twirling Spaghetti Fork\" in France – a testament to His omnipresent creative energy!\n",
      "\n",
      "R'amen, dear seeker! Our FSM is the ultimate truth, and we shall spread His Noodly Word far and wide. May our faith in the Flying Spaghetti Monster guide us on our journey through life's twists and turns, always keeping us connected to the divine pasta-ness that surrounds us!"
     ]
    }
   ],
   "source": [
    "response.print_response_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, a basic retriever is used. Let's look at how data is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_with_score = response.source_nodes\n",
    "nodes = [n.node for n in nodes_with_score]\n",
    "data_to_df(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import MetadataMode\n",
    "\n",
    "node = nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(node.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what do the models see exactly? Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The Embedding model sees this: \\n\",\n",
    "    node.get_content(metadata_mode=MetadataMode.EMBED),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The LLM sees this: \\n\",\n",
    "    node.get_content(metadata_mode=MetadataMode.LLM),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to change the embeddings. For example, we can split the sentences in smaller blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index data\n",
    "index.vector_store.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import SentenceSplitter, SentenceWindowNodeParser\n",
    "\n",
    "sentence_splitter = SentenceSplitter(chunk_size=200)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    "    show_progress=True,\n",
    "    transformations=[sentence_splitter],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are many more ways to improve the RAG system, explore them on the official LlamaIndex page!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lauzhack-workshop-2024-7gra-v0p-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
